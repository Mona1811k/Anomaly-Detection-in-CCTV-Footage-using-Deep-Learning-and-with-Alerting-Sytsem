{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mona1811k/Anomaly-Detection-in-CCTV-Footage-using-Deep-Learning-and-with-Alerting-Sytsem/blob/main/smart_ser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2024-12-09T06:59:28.820295Z",
          "iopub.status.busy": "2024-12-09T06:59:28.819919Z",
          "iopub.status.idle": "2024-12-09T06:59:40.013765Z",
          "shell.execute_reply": "2024-12-09T06:59:40.013061Z",
          "shell.execute_reply.started": "2024-12-09T06:59:28.820260Z"
        },
        "trusted": true,
        "id": "YsUaFo5OITPs"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output,Video\n",
        "import keras\n",
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T06:59:40.015694Z",
          "iopub.status.busy": "2024-12-09T06:59:40.015231Z",
          "iopub.status.idle": "2024-12-09T06:59:40.019619Z",
          "shell.execute_reply": "2024-12-09T06:59:40.018728Z",
          "shell.execute_reply.started": "2024-12-09T06:59:40.015667Z"
        },
        "trusted": true,
        "id": "OGR7k_mcITP2"
      },
      "outputs": [],
      "source": [
        "scvd_train_dir = '/kaggle/input/smartcity-cctv-violence-detection-dataset-scvd/SCVD/SCVD_converted_sec_split/Train'\n",
        "scvd_test_dir = '/kaggle/input/smartcity-cctv-violence-detection-dataset-scvd/SCVD/SCVD_converted_sec_split/Test'\n",
        "scvd_classes = ['Normal', 'Violence','Weaponized']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T07:01:50.895042Z",
          "iopub.status.busy": "2024-12-09T07:01:50.894138Z",
          "iopub.status.idle": "2024-12-09T07:01:50.898844Z",
          "shell.execute_reply": "2024-12-09T07:01:50.898046Z",
          "shell.execute_reply.started": "2024-12-09T07:01:50.895012Z"
        },
        "trusted": true,
        "id": "bQsPnwTGITP4"
      },
      "outputs": [],
      "source": [
        "# Define the base directory and categories\n",
        "base_dir = '/kaggle/input/smartcity-cctv-violence-detection-dataset-scvd/SCVD/SCVD_converted_sec_split/Train'\n",
        "categories = ['Normal', 'Violence', 'Weaponized']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T07:01:51.660903Z",
          "iopub.status.busy": "2024-12-09T07:01:51.660566Z",
          "iopub.status.idle": "2024-12-09T07:01:51.829132Z",
          "shell.execute_reply": "2024-12-09T07:01:51.828033Z",
          "shell.execute_reply.started": "2024-12-09T07:01:51.660874Z"
        },
        "trusted": true,
        "id": "kJEhmyyFITP5",
        "outputId": "4935c33e-1f46-4d76-8f5a-65b85c7d1f7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video counts per category:\n",
            "Normal: 872 videos\n",
            "Violence: 970 videos\n",
            "Weaponized: 832 videos\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Function to count videos in each category\n",
        "def count_videos(base_dir, categories):\n",
        "    video_count = {}\n",
        "\n",
        "    for category in categories:\n",
        "        category_path = os.path.join(base_dir, category)\n",
        "\n",
        "        if not os.path.exists(category_path):\n",
        "            print(f\"Directory for category '{category}' not found.\")\n",
        "            video_count[category] = 0\n",
        "            continue\n",
        "\n",
        "        # List all video files in the category directory\n",
        "        video_files = [f for f in os.listdir(category_path) if f.endswith(('.mp4', '.avi', '.mkv'))]\n",
        "        video_count[category] = len(video_files)\n",
        "\n",
        "    return video_count\n",
        "\n",
        "# Call the function and print the counts\n",
        "video_counts = count_videos(base_dir, categories)\n",
        "\n",
        "print(\"Video counts per category:\")\n",
        "for category, count in video_counts.items():\n",
        "    print(f\"{category}: {count} videos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T07:01:52.973635Z",
          "iopub.status.busy": "2024-12-09T07:01:52.973291Z",
          "iopub.status.idle": "2024-12-09T07:01:52.978011Z",
          "shell.execute_reply": "2024-12-09T07:01:52.976987Z",
          "shell.execute_reply.started": "2024-12-09T07:01:52.973608Z"
        },
        "trusted": true,
        "id": "NfEY4UEqITP7"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 50\n",
        "\n",
        "MAX_SEQ_LENGTH = 20\n",
        "NUM_FEATURES = 2048"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T07:01:53.774277Z",
          "iopub.status.busy": "2024-12-09T07:01:53.773923Z",
          "iopub.status.idle": "2024-12-09T07:01:53.778712Z",
          "shell.execute_reply": "2024-12-09T07:01:53.777795Z",
          "shell.execute_reply.started": "2024-12-09T07:01:53.774247Z"
        },
        "trusted": true,
        "id": "YxDzAEP3ITP9"
      },
      "outputs": [],
      "source": [
        "# Define the label mapping\n",
        "label_mapping = {\"Normal\": 0, \"Violence\": 1, \"Weaponized\": 2}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T07:01:54.360726Z",
          "iopub.status.busy": "2024-12-09T07:01:54.360388Z",
          "iopub.status.idle": "2024-12-09T07:01:54.367015Z",
          "shell.execute_reply": "2024-12-09T07:01:54.366192Z",
          "shell.execute_reply.started": "2024-12-09T07:01:54.360698Z"
        },
        "trusted": true,
        "id": "GEYy7HZ_ITP-"
      },
      "outputs": [],
      "source": [
        "def crop_center_square(frame):\n",
        "    y, x = frame.shape[0:2]\n",
        "    min_dim = min(y, x)\n",
        "    start_x = (x // 2) - (min_dim // 2)\n",
        "    start_y = (y // 2) - (min_dim // 2)\n",
        "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
        "\n",
        "\n",
        "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frame = crop_center_square(frame)\n",
        "            frame = cv2.resize(frame, resize)\n",
        "            frame = frame[:, :, [2, 1, 0]]\n",
        "            frames.append(frame)\n",
        "\n",
        "            if len(frames) == max_frames:\n",
        "                break\n",
        "    finally:\n",
        "        cap.release()\n",
        "    return np.array(frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T07:01:55.533764Z",
          "iopub.status.busy": "2024-12-09T07:01:55.533430Z",
          "iopub.status.idle": "2024-12-09T07:02:00.882569Z",
          "shell.execute_reply": "2024-12-09T07:02:00.881832Z",
          "shell.execute_reply.started": "2024-12-09T07:01:55.533736Z"
        },
        "trusted": true,
        "id": "CN8jvHB-ITP_",
        "outputId": "7e9e1757-169d-4f06-9adb-222d6774dfa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "def build_feature_extractor():\n",
        "    feature_extractor = keras.applications.InceptionV3(\n",
        "        weights=\"imagenet\",\n",
        "        include_top=False,\n",
        "        pooling=\"avg\",\n",
        "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "    )\n",
        "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
        "\n",
        "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
        "    preprocessed = preprocess_input(inputs)\n",
        "\n",
        "    outputs = feature_extractor(preprocessed)\n",
        "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
        "\n",
        "\n",
        "feature_extractor = build_feature_extractor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T07:02:00.884981Z",
          "iopub.status.busy": "2024-12-09T07:02:00.884346Z",
          "iopub.status.idle": "2024-12-09T07:02:00.892642Z",
          "shell.execute_reply": "2024-12-09T07:02:00.891640Z",
          "shell.execute_reply.started": "2024-12-09T07:02:00.884939Z"
        },
        "trusted": true,
        "id": "IuIihFziITQA"
      },
      "outputs": [],
      "source": [
        "def prepare_all_videos(df, root_dir):\n",
        "    num_samples = len(df)\n",
        "    video_paths = df[\"original_path\"].values  # Use the 'original_path' column\n",
        "    labels = df[\"label\"].map(label_mapping).values  # Assuming label_mapping is defined\n",
        "\n",
        "    # Initialize placeholders for masks and features\n",
        "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
        "    frame_features = np.zeros(\n",
        "        shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
        "    )\n",
        "\n",
        "    # For each video\n",
        "    for idx, path in enumerate(video_paths):\n",
        "        # Gather all its frames and add a batch dimension\n",
        "        frames = load_video(path)  # Use the full path directly\n",
        "        frames = frames[None, ...]\n",
        "\n",
        "        # Initialize placeholders for the current video's masks and features\n",
        "        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "        temp_frame_features = np.zeros(\n",
        "            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
        "        )\n",
        "\n",
        "        # Extract features from the frames of the current video\n",
        "        for i, batch in enumerate(frames):\n",
        "            video_length = batch.shape[0]\n",
        "            length = min(MAX_SEQ_LENGTH, video_length)\n",
        "            for j in range(length):\n",
        "                temp_frame_features[i, j, :] = feature_extractor.predict(\n",
        "                    batch[None, j, :]\n",
        "                )\n",
        "            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
        "\n",
        "        # Store features and masks for the current video\n",
        "        frame_features[idx,] = temp_frame_features.squeeze()\n",
        "        frame_masks[idx,] = temp_frame_mask.squeeze()\n",
        "\n",
        "    return (frame_features, frame_masks), labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T07:02:00.894602Z",
          "iopub.status.busy": "2024-12-09T07:02:00.893998Z",
          "iopub.status.idle": "2024-12-09T07:02:01.330702Z",
          "shell.execute_reply": "2024-12-09T07:02:01.329733Z",
          "shell.execute_reply.started": "2024-12-09T07:02:00.894565Z"
        },
        "trusted": true,
        "id": "bNdiF5yeITQB",
        "outputId": "0f4491c9-a678-46aa-8aa3-ddeb96ee31ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample of train_sample_metadata:\n",
            "                                       original_path   label\n",
            "0  /kaggle/input/smartcity-cctv-violence-detectio...  Normal\n",
            "1  /kaggle/input/smartcity-cctv-violence-detectio...  Normal\n",
            "2  /kaggle/input/smartcity-cctv-violence-detectio...  Normal\n",
            "3  /kaggle/input/smartcity-cctv-violence-detectio...  Normal\n",
            "4  /kaggle/input/smartcity-cctv-violence-detectio...  Normal\n",
            "Train and Test set shapes:\n",
            "(2406, 2) (268, 2)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Base directory for the dataset\n",
        "base_dir = '/kaggle/input/smartcity-cctv-violence-detection-dataset-scvd/SCVD/SCVD_converted_sec_split/Train'\n",
        "\n",
        "# Define the class labels\n",
        "categories = ['Normal', 'Violence', 'Weaponized']\n",
        "\n",
        "# Initialize a list to store metadata\n",
        "metadata = []\n",
        "\n",
        "# Traverse through each category\n",
        "for category in categories:\n",
        "    category_path = os.path.join(base_dir, category)\n",
        "    if not os.path.exists(category_path):\n",
        "        print(f\"Category directory '{category}' not found!\")\n",
        "        continue\n",
        "\n",
        "    # List all video files in the category directory\n",
        "    video_files = [f for f in os.listdir(category_path) if f.endswith(('.mp4', '.avi', '.mkv'))]\n",
        "    for video_file in video_files:\n",
        "        # Create full path to the video\n",
        "        video_path = os.path.join(category_path, video_file)\n",
        "        # Append metadata\n",
        "        metadata.append({'original_path': video_path, 'label': category})\n",
        "\n",
        "# Create a DataFrame from the metadata\n",
        "train_sample_metadata = pd.DataFrame(metadata)\n",
        "\n",
        "# Display the first few rows\n",
        "print(\"Sample of train_sample_metadata:\")\n",
        "print(train_sample_metadata.head())\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Train_set, Test_set = train_test_split(\n",
        "    train_sample_metadata,\n",
        "    test_size=0.1,\n",
        "    random_state=42,\n",
        "    stratify=train_sample_metadata['label']\n",
        ")\n",
        "\n",
        "print(\"Train and Test set shapes:\")\n",
        "print(Train_set.shape, Test_set.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "vvH2OAmIITQL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 2151340,
          "sourceId": 7312675,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30805,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}